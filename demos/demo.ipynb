{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSL-Net: Feature Shift Localization Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use a pre-trained Feature Shift Localization Network (FSL-Net) to identify feature-level changes between a reference and a manipulated query dataset. The goal is to localize which features have been modified. We will:\n",
    "\n",
    "1. Load a pre-trained FSL-Net model\n",
    "2. Load the reference and manipulated query datasets\n",
    "3. Run inference\n",
    "4. Evaluate the model's performance using F1 Score and runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "sys.path.append('../')\n",
    "from fslnet.fslnet import FSLNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Setup\n",
    "\n",
    "Select the computation device (GPU if available) and define dataset paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Automatically select GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Paths to data files\n",
    "ref_path = './data/references/covid_0.1_E1_ref.npy'\n",
    "que_path = './data/queries/covid_0.1_E1_que.npy'\n",
    "C_positions_path = './data/C_positions/covid_0.1_E1_C_positions.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Load Pre-trained FSL-Net\n",
    "\n",
    "Load the FSL-Net model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Loading FSLNet weights from '/private/home/mbarrabe/FSL-Net/demos/../fslnet/checkpoints/fslnet.pth' onto cpu ...\n",
      "--> FSLNet loaded and set to eval().\n"
     ]
    }
   ],
   "source": [
    "fslnet = FSLNet.from_pretrained(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Load Reference, Query, and Shifted Features\n",
    "\n",
    "Load the reference, query, and shifted feature indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_path = '/private/home/mbarrabe/FSL-Net/data/references/covid_0.1_E1_ref.npy'\n",
    "que_path = '/private/home/mbarrabe/FSL-Net/data/queries/covid_0.1_E1_que.npy'\n",
    "C_positions_path = '/private/home/mbarrabe/FSL-Net/data/C_positions/covid_0.1_E1_C_positions.npy'\n",
    "\n",
    "ref = torch.tensor(np.load(ref_path), dtype=torch.float32)\n",
    "que = torch.tensor(np.load(que_path), dtype=torch.float32)\n",
    "C_positions = torch.tensor(np.load(C_positions_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Inference & Evaluation\n",
    "\n",
    "Run FSL-Net on the reference and query sets, then evaluate the F1 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 1.0\n",
      "Runtime (seconds): 0.18433022499084473\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    soft_predictions, _ = fslnet(ref, que)        # Corruption probabilities\n",
    "    hard_predictions = (soft_predictions > 0.5)  # Boolean mask â€” True = shifted\n",
    "    end_time = time.time()\n",
    "\n",
    "runtime = end_time - start_time\n",
    "\n",
    "# Create ground truth tensor\n",
    "target = torch.zeros(1, que.shape[1]).to(device)\n",
    "target[0, C_positions] = 1\n",
    "\n",
    "# Compute F1 Score\n",
    "f1 = f1_score(target.squeeze(), hard_predictions.squeeze(), zero_division=1)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Runtime (seconds):\", runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
